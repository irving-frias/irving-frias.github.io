
        # robots.txt file generated by Webpack build

        # Allow all crawlers to access everything
        User-agent: *
        Disallow:

        # Noindex the /private/ folder (Example: You can specify URLs you want to be excluded from indexing)
        User-agent: *
        Disallow: /private/

        # End of robots.txt
    